{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_path = 'model/keywords_aminer_zh'\n",
    "en_path = 'model/keywords_aminer_en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithm design and analysis', 0.7523155212402344), ('classification algorithms', 0.6936554908752441), ('data models', 0.6934263110160828), ('knowledge discovery', 0.6912256479263306), ('information analysis', 0.6770250201225281), ('computational modeling', 0.6744495630264282), ('association rules', 0.6620141267776489), ('commodities interflow', 0.6523971557617188), ('frequent closed itemset mining', 0.6514651775360107), ('learning artificial intelligence', 0.6466258764266968)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_en = KeyedVectors.load(en_path)\n",
    "\n",
    "# print(model_en[\"data mining\"])\n",
    "print(model_en.most_similar(\"data mining\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('关联规则', 0.9038501381874084), ('apriori算法', 0.8566242456436157), ('知识发现', 0.8078784346580505), ('频繁项集', 0.794908881187439), ('数据仓库', 0.7892417907714844), ('apriori', 0.7818102240562439), ('联机分析处理', 0.7706191539764404), ('fp-growth', 0.7693448066711426), ('数据挖掘技术', 0.7669618129730225), ('挖掘算法', 0.7620916366577148)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_zh = KeyedVectors.load(zh_path)\n",
    "\n",
    "# print(model_zh[\"数据挖掘\"])\n",
    "print(model_zh.most_similar(\"数据挖掘\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qingsong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/qingsong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qingsong/.local/lib/python3.6/site-packages/jieba/__init__.py\", line 152, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmpsr7aucl4' -> '/tmp/jieba.cache'\n",
      "Loading model cost 0.920 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['机器翻译', '是', '自然语言处理', '的', '一个', '子领域']\n",
      "['machine translation', 'is a', 'sub-domain', 'of', 'natural language processing', '.']\n"
     ]
    }
   ],
   "source": [
    "from src.tokenizer import tokenizer, zh_process_func, en_process_func\n",
    "\n",
    "tok_zh = tokenizer(set(model_zh.wv.index2word), zh_process_func)\n",
    "tok_en = tokenizer(set(model_en.wv.index2word), en_process_func)\n",
    "\n",
    "print(tok_zh.tokenize(\"机器翻译是自然语言处理的一个子领域。\", max_len=None))\n",
    "print(tok_en.tokenize(\"Machine translation is a sub-domain of natural language processing.\", max_len=None)) # Maybe you need nltk.download('punkt') if failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['机器翻译', '自然语言处理', '子领域']\n",
      "['machine translation', 'natural language processing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qingsong/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.distill import distill\n",
    "\n",
    "words = tok_zh.tokenize(\"机器翻译是自然语言处理的一个子领域。\")\n",
    "print(distill(model_zh, words, lang='zh'))\n",
    "words = tok_en.tokenize(\"Machine translation is a sub-domain of natural language processing.\")\n",
    "print(distill(model_en, words, lang='en'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
